{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load CSV & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain.\\n\\nThe FW generator is a high-tem...</td>\n",
       "      <td>['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain. Based on the given package list ...</td>\n",
       "      <td>['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain!\\n\\nAccording to the PACKAGE LIST ...</td>\n",
       "      <td>['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain. \\n\\nThe FW generator is a low pre...</td>\n",
       "      <td>['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0  what is the feature of FW generator?   \n",
       "1  what is the feature of FW generator?   \n",
       "2  what is the feature of FW generator?   \n",
       "3  what is the feature of FW generator?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  OK, Captain.\\n\\nThe FW generator is a high-tem...   \n",
       "1   OK, Captain. Based on the given package list ...   \n",
       "2  OK, Captain!\\n\\nAccording to the PACKAGE LIST ...   \n",
       "3  OK, Captain. \\n\\nThe FW generator is a low pre...   \n",
       "\n",
       "                                            contexts ground_truth  \n",
       "0  ['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...               \n",
       "1  ['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...               \n",
       "2  ['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...               \n",
       "3  ['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : 0...               "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df = pd.read_csv(\"../results/test_003.csv\")\n",
    "t_df = t_df[[\"Query\", \"Answer\", \"Context\"]]\n",
    "t_df.columns = ['question', 'answer', 'contexts']\n",
    "t_df['ground_truth'] = \"\"\n",
    "t_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>contexts</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain.\\n\\nThe FW generator is a high-tem...</td>\n",
       "      <td>[['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain. Based on the given package list ...</td>\n",
       "      <td>[['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain!\\n\\nAccording to the PACKAGE LIST ...</td>\n",
       "      <td>[['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what is the feature of FW generator?</td>\n",
       "      <td>OK, Captain. \\n\\nThe FW generator is a low pre...</td>\n",
       "      <td>[['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0  what is the feature of FW generator?   \n",
       "1  what is the feature of FW generator?   \n",
       "2  what is the feature of FW generator?   \n",
       "3  what is the feature of FW generator?   \n",
       "\n",
       "                                              answer  \\\n",
       "0  OK, Captain.\\n\\nThe FW generator is a high-tem...   \n",
       "1   OK, Captain. Based on the given package list ...   \n",
       "2  OK, Captain!\\n\\nAccording to the PACKAGE LIST ...   \n",
       "3  OK, Captain. \\n\\nThe FW generator is a low pre...   \n",
       "\n",
       "                                            contexts ground_truth  \n",
       "0  [['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...               \n",
       "1  [['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...               \n",
       "2  [['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...               \n",
       "3  [['PACKAGE LIST\\\\nHULL NO. : 8250/8251 PAGE : ...               "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_df[\"contexts\"] = t_df[\"contexts\"].astype(str).apply(lambda x: [x] if x else [])\n",
    "t_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to Huggingfase Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def pandas_to_ragas(df):\n",
    "    '''\n",
    "    Converts a Pandas DataFrame into a Ragas-compatible dataset\n",
    "    \n",
    "    Inputs:\n",
    "        - df (Pandas DataFrame): The input DataFrame to be converted\n",
    "        \n",
    "    Returns:\n",
    "        - ragas_testset (Hugging Face Dataset): A Hugging Face dataset compatible with the Ragas framework\n",
    "    '''\n",
    "    # Ensure all text columns are strings and handle NaN values\n",
    "    text_columns = ['question', 'ground_truth', 'answer']\n",
    "    for col in text_columns:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "        \n",
    "    # Convert 'contexts' to a list of lists\n",
    "    df['contexts'] = df['contexts'].fillna('').astype(str).apply(lambda x: [x] if x else [])\n",
    "    \n",
    "    # Converting the DataFrame to a dictionary\n",
    "    data_dict = df[['question', 'contexts', 'answer', 'ground_truth']].to_dict('list')\n",
    "    \n",
    "    # Loading the dictionary as a Hugging Face dataset\n",
    "    ragas_testset = Dataset.from_dict(data_dict)\n",
    "    \n",
    "    return ragas_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'contexts', 'answer', 'ground_truth'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_testset = pandas_to_ragas(df = t_df)\n",
    "ragas_testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['[\"[\\'PACKAGE LIST\\\\\\\\\\\\\\\\nHULL NO. : 8250/8251 PAGE : 0\\\\\\\\\\\\\\\\nPOR NO.\\\\\\\\\\\\\\\\nSER. SEQ. DESCRIPTION Qâ€™TY REMARK\\\\\\\\\\\\\\\\nNO. NO.\\\\\\\\\\\\\\\\nM536 AA F.W. GENERATOR EVAPORATING TYPE 1 Separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nM536 BB SPARE PARTS & TOOLS FOR F.W. GENERATOR 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. EACH UNIT WITHIN A PACKAGE OR SHIPPING CONTAINER SHALL BE\\\\\\\\\\\\\\\\nCLEARLY MARKED IN A MANNER AS MAY BE DESIGNATED BY THE BUYER\\\\\\\\\\\\\\\\nBY STAMPING, TAGGING OR OTHER SUITABLE MEANS WITH\\\\\\\\\\\\\\\\nIDENTIFICATION OF SUPPLY.\\\\\\\\\\\\\\\\nTHE OUTSIDE OF EACH PACKAGE AND OR PROTECTIVE DEVICES SHALL\\\\\\\\\\\\\\\\nBE CLEARLY MARKED, REFERING SHIPPING MARK.\\\\\\\\\\\\\\\\n2. ABOVE POR NO. (SER. NO. - SEQ. NO.) AND DESCRIPTION MUST BE\\\\\\\\\\\\\\\\nMARKED ON EACH PACKAGE AND PACKING LIST.\\', None, \\'the approval drawing.\\\\\\\\\\\\\\\\n20) Eye-plate to be suitably fitted for rotor of generator, steam turbines, electric motors,\\\\\\\\\\\\\\\\nheat exchangerâ€™s cover/tube/bundles and heavy strainerâ€™s cover/filter/element of about\\\\\\\\\\\\\\\\n40 kg & above (And lifting eyes to have a min. diameter of 23 mm).\\\\\\\\\\\\\\\\n21) Test provision such as three way test cock to be provided for pressure switches and\\\\\\\\\\\\\\\\npressure transmitters.\\']\"]'],\n",
       " ['[\"[\\'PACKAGE LIST\\\\\\\\\\\\\\\\nHULL NO. : 8250/8251 PAGE : 0\\\\\\\\\\\\\\\\nPOR NO.\\\\\\\\\\\\\\\\nSER. SEQ. DESCRIPTION Qâ€™TY REMARK\\\\\\\\\\\\\\\\nNO. NO.\\\\\\\\\\\\\\\\nM536 AA F.W. GENERATOR EVAPORATING TYPE 1 Separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nM536 BB SPARE PARTS & TOOLS FOR F.W. GENERATOR 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. EACH UNIT WITHIN A PACKAGE OR SHIPPING CONTAINER SHALL BE\\\\\\\\\\\\\\\\nCLEARLY MARKED IN A MANNER AS MAY BE DESIGNATED BY THE BUYER\\\\\\\\\\\\\\\\nBY STAMPING, TAGGING OR OTHER SUITABLE MEANS WITH\\\\\\\\\\\\\\\\nIDENTIFICATION OF SUPPLY.\\\\\\\\\\\\\\\\nTHE OUTSIDE OF EACH PACKAGE AND OR PROTECTIVE DEVICES SHALL\\\\\\\\\\\\\\\\nBE CLEARLY MARKED, REFERING SHIPPING MARK.\\\\\\\\\\\\\\\\n2. ABOVE POR NO. (SER. NO. - SEQ. NO.) AND DESCRIPTION MUST BE\\\\\\\\\\\\\\\\nMARKED ON EACH PACKAGE AND PACKING LIST.\\', None, \\'the approval drawing.\\\\\\\\\\\\\\\\n20) Eye-plate to be suitably fitted for rotor of generator, steam turbines, electric motors,\\\\\\\\\\\\\\\\nheat exchangerâ€™s cover/tube/bundles and heavy strainerâ€™s cover/filter/element of about\\\\\\\\\\\\\\\\n40 kg & above (And lifting eyes to have a min. diameter of 23 mm).\\\\\\\\\\\\\\\\n21) Test provision such as three way test cock to be provided for pressure switches and\\\\\\\\\\\\\\\\npressure transmitters.\\']\"]'],\n",
       " ['[\"[\\'PACKAGE LIST\\\\\\\\\\\\\\\\nHULL NO. : 8250/8251 PAGE : 0\\\\\\\\\\\\\\\\nPOR NO.\\\\\\\\\\\\\\\\nSER. SEQ. DESCRIPTION Qâ€™TY REMARK\\\\\\\\\\\\\\\\nNO. NO.\\\\\\\\\\\\\\\\nM536 AA F.W. GENERATOR EVAPORATING TYPE 1 Separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nM536 BB SPARE PARTS & TOOLS FOR F.W. GENERATOR 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. EACH UNIT WITHIN A PACKAGE OR SHIPPING CONTAINER SHALL BE\\\\\\\\\\\\\\\\nCLEARLY MARKED IN A MANNER AS MAY BE DESIGNATED BY THE BUYER\\\\\\\\\\\\\\\\nBY STAMPING, TAGGING OR OTHER SUITABLE MEANS WITH\\\\\\\\\\\\\\\\nIDENTIFICATION OF SUPPLY.\\\\\\\\\\\\\\\\nTHE OUTSIDE OF EACH PACKAGE AND OR PROTECTIVE DEVICES SHALL\\\\\\\\\\\\\\\\nBE CLEARLY MARKED, REFERING SHIPPING MARK.\\\\\\\\\\\\\\\\n2. ABOVE POR NO. (SER. NO. - SEQ. NO.) AND DESCRIPTION MUST BE\\\\\\\\\\\\\\\\nMARKED ON EACH PACKAGE AND PACKING LIST.\\', None, \\'the approval drawing.\\\\\\\\\\\\\\\\n20) Eye-plate to be suitably fitted for rotor of generator, steam turbines, electric motors,\\\\\\\\\\\\\\\\nheat exchangerâ€™s cover/tube/bundles and heavy strainerâ€™s cover/filter/element of about\\\\\\\\\\\\\\\\n40 kg & above (And lifting eyes to have a min. diameter of 23 mm).\\\\\\\\\\\\\\\\n21) Test provision such as three way test cock to be provided for pressure switches and\\\\\\\\\\\\\\\\npressure transmitters.\\']\"]'],\n",
       " ['[\"[\\'PACKAGE LIST\\\\\\\\\\\\\\\\nHULL NO. : 8250/8251 PAGE : 0\\\\\\\\\\\\\\\\nPOR NO.\\\\\\\\\\\\\\\\nSER. SEQ. DESCRIPTION Qâ€™TY REMARK\\\\\\\\\\\\\\\\nNO. NO.\\\\\\\\\\\\\\\\nM536 AA F.W. GENERATOR EVAPORATING TYPE 1 Separately\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\nM536 BB SPARE PARTS & TOOLS FOR F.W. GENERATOR 1\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n\\\\\\\\\\\\\\\\n1. EACH UNIT WITHIN A PACKAGE OR SHIPPING CONTAINER SHALL BE\\\\\\\\\\\\\\\\nCLEARLY MARKED IN A MANNER AS MAY BE DESIGNATED BY THE BUYER\\\\\\\\\\\\\\\\nBY STAMPING, TAGGING OR OTHER SUITABLE MEANS WITH\\\\\\\\\\\\\\\\nIDENTIFICATION OF SUPPLY.\\\\\\\\\\\\\\\\nTHE OUTSIDE OF EACH PACKAGE AND OR PROTECTIVE DEVICES SHALL\\\\\\\\\\\\\\\\nBE CLEARLY MARKED, REFERING SHIPPING MARK.\\\\\\\\\\\\\\\\n2. ABOVE POR NO. (SER. NO. - SEQ. NO.) AND DESCRIPTION MUST BE\\\\\\\\\\\\\\\\nMARKED ON EACH PACKAGE AND PACKING LIST.\\', None, \\'the approval drawing.\\\\\\\\\\\\\\\\n20) Eye-plate to be suitably fitted for rotor of generator, steam turbines, electric motors,\\\\\\\\\\\\\\\\nheat exchangerâ€™s cover/tube/bundles and heavy strainerâ€™s cover/filter/element of about\\\\\\\\\\\\\\\\n40 kg & above (And lifting eyes to have a min. diameter of 23 mm).\\\\\\\\\\\\\\\\n21) Test provision such as three way test cock to be provided for pressure switches and\\\\\\\\\\\\\\\\npressure transmitters.\\']\"]']]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ragas_testset[\"contexts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ragas Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "metrics=[\n",
    "    answer_relevancy,\n",
    "    answer_correctness,\n",
    "    answer_similarity,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    ],"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval with ChatGPT(3.5 and 4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe7c6fff70245c39e1febff1180ea12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The LLM did not return a valid classification.\n",
      "The LLM did not return a valid classification.\n",
      "The LLM did not return a valid classification.\n",
      "The LLM did not return a valid classification.\n",
      "d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\evaluation.py:304: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.6577, 'answer_correctness': 0.1600, 'answer_similarity': 0.6399, 'faithfulness': 0.0839, 'context_precision': 0.0000, 'context_recall': nan}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "# llm = ChatOpenAI(model = 'gpt-3.5-turbo')\n",
    "llm = ChatOpenAI(model = 'gpt-4o')\n",
    "\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "naive_results = evaluate(\n",
    "    ragas_testset, \n",
    "    metrics = [\n",
    "        answer_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm = llm,\n",
    "    embeddings=embeddings,\n",
    "    raise_exceptions=False)\n",
    "\n",
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval with Groq API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1674c159788840df851ef30ecd149304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 35, in _parse_obj\n",
      "    return self.pydantic_object.parse_obj(obj)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\pydantic\\v1\\main.py\", line 526, in parse_obj\n",
      "    return cls(**obj)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\pydantic\\v1\\main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 1 validation error for StatementsAnswers\n",
      "__root__\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\output_parser.py\", line 61, in aparse\n",
      "    output = super().parse(result)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 64, in parse\n",
      "    return super().parse(text)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\json.py\", line 72, in parse\n",
      "    return self.parse_result([Generation(text=text)])\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 61, in parse_result\n",
      "    return self._parse_obj(json_object)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 42, in _parse_obj\n",
      "    raise self._parser_exception(e, obj)\n",
      "langchain_core.exceptions.OutputParserException: Failed to parse StatementsAnswers from completion null. Got: 1 validation error for StatementsAnswers\n",
      "__root__\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 253, in _ascore\n",
      "    statements = await _statements_output_parser.aparse(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\output_parser.py\", line 67, in aparse\n",
      "    output = await llm.generate(p_value)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 250, in _ascore\n",
      "    is_statement_present = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 35, in _parse_obj\n",
      "    return self.pydantic_object.parse_obj(obj)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\pydantic\\v1\\main.py\", line 526, in parse_obj\n",
      "    return cls(**obj)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\pydantic\\v1\\main.py\", line 341, in __init__\n",
      "    raise validation_error\n",
      "pydantic.v1.error_wrappers.ValidationError: 1 validation error for StatementsAnswers\n",
      "__root__\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\output_parser.py\", line 61, in aparse\n",
      "    output = super().parse(result)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 64, in parse\n",
      "    return super().parse(text)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\json.py\", line 72, in parse\n",
      "    return self.parse_result([Generation(text=text)])\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 61, in parse_result\n",
      "    return self._parse_obj(json_object)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\output_parsers\\pydantic.py\", line 42, in _parse_obj\n",
      "    raise self._parser_exception(e, obj)\n",
      "langchain_core.exceptions.OutputParserException: Failed to parse StatementsAnswers from completion null. Got: 1 validation error for StatementsAnswers\n",
      "__root__\n",
      "  none is not an allowed value (type=type_error.none.not_allowed)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 224, in _ascore\n",
      "    statements[item] = await _statements_output_parser.aparse(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\output_parser.py\", line 67, in aparse\n",
      "    output = await llm.generate(p_value)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 266, in _ascore\n",
      "    nli_result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 57, in __call__\n",
      "    await self.sleep(do)\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 605, in sleep\n",
      "    return await future\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\evaluation.py:304: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': 0.6733, 'answer_correctness': nan, 'answer_similarity': 0.6966, 'faithfulness': nan, 'context_precision': 0.0000, 'context_recall': 0.5556}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(name=\"gemma2-9b-it\")   \n",
    "# llm = ChatGroq(name=\"llama3-8b-8192\")  \n",
    "llm = ChatGroq(name=\"llama3-70b-8192\") \n",
    "#  \n",
    "naive_results = evaluate(\n",
    "    ragas_testset, \n",
    "    metrics = [\n",
    "        answer_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm = llm,\n",
    "    embeddings=embeddings,\n",
    "    raise_exceptions=False)\n",
    "\n",
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval with Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc05af639e54b0b8794224ddb624888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 26, in embed_text\n",
      "    embs = await self.embed_texts([text], is_async=is_async)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 36, in embed_texts\n",
      "    return await aembed_documents_with_retry(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 67, in aembed_documents\n",
      "    return await self.embeddings.aembed_documents(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\embeddings\\embeddings.py\", line 21, in aembed_documents\n",
      "    return await run_in_executor(None, self.embed_documents, texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 557, in run_in_executor\n",
      "    return await asyncio.get_running_loop().run_in_executor(\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 26, in embed_text\n",
      "    embs = await self.embed_texts([text], is_async=is_async)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 36, in embed_texts\n",
      "    return await aembed_documents_with_retry(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 67, in aembed_documents\n",
      "    return await self.embeddings.aembed_documents(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\embeddings\\embeddings.py\", line 21, in aembed_documents\n",
      "    return await run_in_executor(None, self.embed_documents, texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 557, in run_in_executor\n",
      "    return await asyncio.get_running_loop().run_in_executor(\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 26, in embed_text\n",
      "    embs = await self.embed_texts([text], is_async=is_async)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 36, in embed_texts\n",
      "    return await aembed_documents_with_retry(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 67, in aembed_documents\n",
      "    return await self.embeddings.aembed_documents(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\embeddings\\embeddings.py\", line 21, in aembed_documents\n",
      "    return await run_in_executor(None, self.embed_documents, texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 557, in run_in_executor\n",
      "    return await asyncio.get_running_loop().run_in_executor(\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_similarity.py\", line 66, in _ascore\n",
      "    embedding_2 = np.array(await self.embeddings.embed_text(answer))\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 26, in embed_text\n",
      "    embs = await self.embed_texts([text], is_async=is_async)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 36, in embed_texts\n",
      "    return await aembed_documents_with_retry(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\embeddings\\base.py\", line 67, in aembed_documents\n",
      "    return await self.embeddings.aembed_documents(texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\embeddings\\embeddings.py\", line 21, in aembed_documents\n",
      "    return await run_in_executor(None, self.embed_documents, texts)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 557, in run_in_executor\n",
      "    return await asyncio.get_running_loop().run_in_executor(\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 314, in _acreate_stream\n",
      "    async for line in response.content:\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 50, in __anext__\n",
      "    rv = await self.read_func()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 317, in readline\n",
      "    return await self.readuntil()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 351, in readuntil\n",
      "    await self._wait(\"readuntil\")\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 312, in _wait\n",
      "    await waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 314, in _acreate_stream\n",
      "    async for line in response.content:\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 50, in __anext__\n",
      "    rv = await self.read_func()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 317, in readline\n",
      "    return await self.readuntil()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 351, in readuntil\n",
      "    await self._wait(\"readuntil\")\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 312, in _wait\n",
      "    await waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_relevance.py\", line 152, in _ascore\n",
      "    result = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_recall.py\", line 169, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 314, in _acreate_stream\n",
      "    async for line in response.content:\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 50, in __anext__\n",
      "    rv = await self.read_func()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 317, in readline\n",
      "    return await self.readuntil()\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 351, in readuntil\n",
      "    await self._wait(\"readuntil\")\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 312, in _wait\n",
      "    await waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_answer_correctness.py\", line 221, in _ascore\n",
      "    item_statement = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_faithfulness.py\", line 248, in _ascore\n",
      "    statements = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "Runner in Executor raised an exception\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 754, in _agenerate_with_cache\n",
      "    result = await self._agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 323, in _agenerate\n",
      "    final_chunk = await self._achat_stream_with_aggregation(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 244, in _achat_stream_with_aggregation\n",
      "    async for stream_resp in self._acreate_chat_stream(messages, stop, **kwargs):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\chat_models\\ollama.py\", line 203, in _acreate_chat_stream\n",
      "    async for stream_resp in self._acreate_stream(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_community\\llms\\ollama.py\", line 294, in _acreate_stream\n",
      "    async with session.post(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 1197, in __aenter__\n",
      "    self._resp = await self._coro\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client.py\", line 608, in _request\n",
      "    await resp.start(conn)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\client_reqrep.py\", line 976, in start\n",
      "    message, payload = await protocol.read()  # type: ignore[union-attr]\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\aiohttp\\streams.py\", line 640, in read\n",
      "    await self._waiter\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 285, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 234, in __step\n",
      "    result = coro.throw(exc)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\_context_precision.py\", line 161, in _ascore\n",
      "    results = await self.llm.generate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 93, in generate\n",
      "    return await agenerate_text_with_retry(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 88, in async_wrapped\n",
      "    return await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 47, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\__init__.py\", line 314, in iter\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 451, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\python\\lib\\concurrent\\futures\\_base.py\", line 403, in __get_result\n",
      "    raise self._exception\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\tenacity\\_asyncio.py\", line 50, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\llms\\base.py\", line 178, in agenerate_text\n",
      "    result = await self.langchain_llm.agenerate_prompt(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 609, in agenerate_prompt\n",
      "    return await self.agenerate(\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 535, in agenerate\n",
      "    results = await asyncio.gather(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 304, in __wakeup\n",
      "    future.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 456, in wait_for\n",
      "    return fut.result()\n",
      "  File \"D:\\python\\lib\\asyncio\\futures.py\", line 196, in result\n",
      "    raise exc\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\executor.py\", line 104, in wrapped_callable_async\n",
      "    result = await callable(*args, **kwargs)\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 134, in ascore\n",
      "    raise e\n",
      "  File \"d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\metrics\\base.py\", line 127, in ascore\n",
      "    score = await asyncio.wait_for(\n",
      "  File \"D:\\python\\lib\\asyncio\\tasks.py\", line 458, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n",
      "d:\\ai_jarvis\\jarvis_env\\lib\\site-packages\\ragas\\evaluation.py:304: RuntimeWarning: Mean of empty slice\n",
      "  value = np.nanmean(self.scores[cn])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'answer_relevancy': nan, 'answer_correctness': nan, 'answer_similarity': nan, 'faithfulness': nan, 'context_precision': 0.0000, 'context_recall': nan}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "llm = ChatOllama(model=\"phi3:latest\")\n",
    "\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "\n",
    "naive_results = evaluate(\n",
    "    ragas_testset, \n",
    "    metrics = [\n",
    "        answer_relevancy,\n",
    "        answer_correctness,\n",
    "        answer_similarity,\n",
    "        faithfulness,\n",
    "        context_precision,\n",
    "        context_recall,\n",
    "    ],\n",
    "    llm = llm,\n",
    "    embeddings=embeddings,\n",
    "    raise_exceptions=False)\n",
    "\n",
    "naive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
